
**ğŸš€ AI-Driven Regression & Load Testing Automation Platform using GenAI (Groq LLaMA 3.1)**

 **ğŸ“Œ Introduction**
 
This project delivers a **robust AI-powered testing automation platform** that combines **Regression Testing** and **Load Testing** into a unified solution.  
It leverages **Groqâ€™s LLaMA 3.1 API** for AI-driven script generation, **Selenium + PyTest** for regression testing, and **Locust** for load testing â€” all controlled via a **Streamlit dashboard** with **Jenkins CI/CD** integration.
---
**ğŸ‘¨â€ğŸ’» Team â€“ Hacktastic Squad**

Renuka S â€“ Project Lead & GenAI Integration

Priyadharshini J â€“ Load Testing & Performance

Rajavel P â€“ Regression Automation

Sangavi K â€“ Frontend & Dashboard

Lathika P â€“ Reporting & Documentation

---
**âœ… Regression Testing**

- AI-generated PyTest test cases from web forms
- Page Object Model (POM) for scalability
- Multi-browser support (Chrome, Firefox, Edge)
- Automatic screenshots for failed tests
- Rich Allure HTML reports with visual debugging
- Google Drive & Email integration for report sharing


**âœ… Load Testing**

- AI-generated Locust scripts for APIs (DummyJSON, FakeStoreAPI, FakeApiNet)
- CRUD operation detection for APIs
- Parallel execution across multiple hosts
- Real-time logs & failure detection
- HTML performance reports with email delivery



**âœ… CI/CD & Automation**

- Jenkins scheduled builds and test execution
- Allure & HTML Publisher plugins for hosted reports
- Email Extension plugin for automated notifications
- Secure credential handling using `.gitignore`


ğŸš€ How to Run

ğŸ”¹ Regression Testing
cd Regression_testing
streamlit run app1.py

ğŸ”¹ Load Testing
cd Load_Testing
streamlit run main.py

ğŸ“ˆ Reporting
Allure Reports â†’ Pass/Fail status, screenshots, execution time, metadata
HTML Reports â†’ Performance metrics for load tests

=======
**ğŸ“‚ Folder Structure (Visual Tree)**
```plaintext
Automation_Testing/
â”œâ”€â”€ Regression_testing/
â”‚   â”œâ”€â”€ Output/                  # Pytest results & reports
â”‚   â”œâ”€â”€ Pages/                   # Page Object Model files
â”‚   â”‚   â”œâ”€â”€ base_page.py
â”‚   â”‚   â”œâ”€â”€ checkout_page.py
â”‚   â”‚   â”œâ”€â”€ footer_page.py
â”‚   â”‚   â”œâ”€â”€ login_page.py
â”‚   â”‚   â”œâ”€â”€ product_page.py
â”‚   â”œâ”€â”€ pytest_report/            # Allure/HTML reports
â”‚   â”œâ”€â”€ Screenshots/              # Failure screenshots
â”‚   â”œâ”€â”€ test1/ test2/ test3/ test4/
â”‚   â”‚   â”œâ”€â”€ allure-report/
â”‚   â”‚   â”œâ”€â”€ allure-results/
â”‚   â”‚   â”œâ”€â”€ pytest_report/
â”‚   â”‚   â”œâ”€â”€ screenshots/
â”‚   â”‚   â”œâ”€â”€ client_secret.json
â”‚   â”‚   â”œâ”€â”€ secrets.json
â”‚   â”‚   â”œâ”€â”€ token.pkl
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ test_computing_and_interaactivity.py
â”‚   â”‚   â”œâ”€â”€ test_parameterize_demowebshop.py
â”‚   â”‚   â”œâ”€â”€ test_parameerize_maincategories.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ form_extractor1.py
â”‚   â”‚   â”œâ”€â”€ test_case_generator1.py
â”‚   â”œâ”€â”€ app1.py                   # Streamlit dashboard UI
â”‚   â”œâ”€â”€ confest1.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.json
â”‚
â”œâ”€â”€ Load_Testing/
â”‚   â”œâ”€â”€ locust_reports/           # Load test HTML reports
â”‚   â”œâ”€â”€ locust_scripts/           # AI-generated Locust scripts
â”‚   â”œâ”€â”€ logs/                     # Execution logs
â”‚   â”‚   â”œâ”€â”€ failed_hosts.txt
â”‚   â”œâ”€â”€ ai_generator.py
â”‚   â”œâ”€â”€ generate_locust_code.py
â”‚   â”œâ”€â”€ locust_scheduler.py
â”‚   â”œâ”€â”€ locustfile.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ run_test.py
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ secrets.json
â”‚   â”œâ”€â”€ locust_output.log

ğŸš€ How to Run

ğŸ”¹ Regression Testing
cd Regression_testing
streamlit run app1.py

ğŸ”¹ Load Testing
cd Load_Testing
streamlit run main.py

ğŸ“ˆ Reporting
Allure Reports â†’ Pass/Fail status, screenshots, execution time, metadata
HTML Reports â†’ Performance metrics for load tests
Reports auto-uploaded to Google Drive & emailed to stakeholders

ğŸ”® Future Enhancements
Slack alert integration
Jira ticket auto-generation
AI-powered self-healing test scripts
Jira ticket auto-generation
AI-powered self-healing test scripts
Grafana/Prometheus dashboards for monitoring

=======

ğŸ“œ Detailed Project Description
Regression Testing
The Selenium Test Automation & Reporting System is an end-to-end automation framework designed to simplify and accelerate the process of generating, executing, and reporting Selenium + Pytest-based test cases.
It integrates browser-based form exploration, AI-powered test case generation, dynamic test execution, and automated Allure reporting â€” all accessible through a Streamlit dashboard, enabling QA teams to automate regression workflows with minimal manual effort.

Key components include:
Form Extractor: Navigates user-defined flows and collects web elements using Selenium WebDriver.
AI Test Generator: Leverages Groqâ€™s LLaMA 3.1 model to create Pytest test functions based on extracted content and scenarios.
Executor & Screenshot Handler: Captures screenshots for failed test cases, automatically embedding them in Allure reports.

Automation Features:
Allure report generator produces rich, interactive HTML reports.
Daily automated test execution and result sharing via Email and Google Drive API.
Jenkins integration with Allure Report, HTML Publisher, and Email Extension plugins.
Follows Page Object Model (POM) for maintainability.
Supports parallel execution with pytest-xdist.
Multi-browser support: Chrome, Edge, Firefox.
Built using Python, Selenium, Pytest, Allure, Streamlit, Groq LLM, and Google Drive API.

Load Testing
The Load Testing Automation System enables intelligent and streamlined performance testing of web applications.
Instead of relying on manually written test scripts, it uses Groqâ€™s LLaMA3 API to automatically generate Locust test scripts tailored to the target website.

Key capabilities:
Supports multiple hosts: DummyJSON, FakeStoreAPI, FakeApiNet.
Automatically detects CRUD operations (Create, Read, Update, Delete).
Parallel execution across multiple APIs for performance comparison.
Configurable test parameters via Streamlit UI (users, spawn rate, duration).
Real-time logs, countdown timers, and failure capture.
Automatic HTML report generation and email delivery.
Supports daily scheduling and automated reporting.

Overall Definition
Our platform delivers a robust AI-driven Regression and Load Testing Automation framework designed for:
Minimal manual effort
Maximum automation
AI-based script generation (Groqâ€™s LLaMA 3.1)
Unified regression & load testing control via Streamlit UI
CI/CD automation with Jenkins
Smart reporting and sharing via Google Drive and Email

Workflow Summary:
User configures tests via Streamlit UI.
AI generates Selenium/PyTest or Locust scripts.
Tests execute (parallel supported).
Reports generated â†’ uploaded â†’ emailed.
Jenkins handles scheduling, automation, and publishing.


